<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11.2 Estimación puntual. | Bioestadistitica-UC.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="11.2 Estimación puntual. | Bioestadistitica-UC.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11.2 Estimación puntual. | Bioestadistitica-UC.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="propiedades-de-un-estimador..html"/>
<link rel="next" href="estimación-por-intervalos..html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="...">Bioestadística.</a></li>
<li><a href="...">Marcelo Molinatti</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="1" data-path="introducción..html"><a href="introducción..html"><i class="fa fa-check"></i><b>1</b> Introducción.</a></li>
<li class="chapter" data-level="2" data-path="teoría-de-probabilidades..html"><a href="teoría-de-probabilidades..html"><i class="fa fa-check"></i><b>2</b> Teoría de Probabilidades.</a></li>
<li class="chapter" data-level="3" data-path="combinatoria..html"><a href="combinatoria..html"><i class="fa fa-check"></i><b>3</b> Combinatoria.</a></li>
<li class="chapter" data-level="4" data-path="otros-teoremas-de-probabilidades..html"><a href="otros-teoremas-de-probabilidades..html"><i class="fa fa-check"></i><b>4</b> Otros Teoremas de Probabilidades.</a></li>
<li class="chapter" data-level="5" data-path="estadística-descriptiva..html"><a href="estadística-descriptiva..html"><i class="fa fa-check"></i><b>5</b> Estadística Descriptiva.</a>
<ul>
<li class="chapter" data-level="5.1" data-path="datos-no-agrupados..html"><a href="datos-no-agrupados..html"><i class="fa fa-check"></i><b>5.1</b> Datos no agrupados.</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="datos-no-agrupados..html"><a href="datos-no-agrupados..html#medidas-de-tendencia-central."><i class="fa fa-check"></i><b>5.1.1</b> Medidas de Tendencia central.</a></li>
<li class="chapter" data-level="5.1.2" data-path="datos-no-agrupados..html"><a href="datos-no-agrupados..html#medidas-de-posición."><i class="fa fa-check"></i><b>5.1.2</b> Medidas de posición.</a></li>
<li class="chapter" data-level="5.1.3" data-path="datos-no-agrupados..html"><a href="datos-no-agrupados..html#medidas-de-dispersión."><i class="fa fa-check"></i><b>5.1.3</b> Medidas de Dispersión.</a></li>
<li class="chapter" data-level="5.1.4" data-path="datos-no-agrupados..html"><a href="datos-no-agrupados..html#medidas-de-forma."><i class="fa fa-check"></i><b>5.1.4</b> Medidas de Forma.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="datos-agrupados..html"><a href="datos-agrupados..html"><i class="fa fa-check"></i><b>5.2</b> Datos Agrupados.</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="datos-agrupados..html"><a href="datos-agrupados..html#medidas-de-tendencia-central.-1"><i class="fa fa-check"></i><b>5.2.1</b> Medidas de Tendencia Central.</a></li>
<li class="chapter" data-level="5.2.2" data-path="datos-agrupados..html"><a href="datos-agrupados..html#medidas-de-posición.-1"><i class="fa fa-check"></i><b>5.2.2</b> Medidas de posición.</a></li>
<li class="chapter" data-level="5.2.3" data-path="datos-agrupados..html"><a href="datos-agrupados..html#medidas-de-dispersión.-1"><i class="fa fa-check"></i><b>5.2.3</b> Medidas de dispersión.</a></li>
<li class="chapter" data-level="5.2.4" data-path="datos-agrupados..html"><a href="datos-agrupados..html#medidas-de-forma.-1"><i class="fa fa-check"></i><b>5.2.4</b> Medidas de forma.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distribuciones-de-probabilidad..html"><a href="distribuciones-de-probabilidad..html"><i class="fa fa-check"></i><b>6</b> Distribuciones de Probabilidad.</a>
<ul>
<li class="chapter" data-level="6.1" data-path="función-de-probabilidad..html"><a href="función-de-probabilidad..html"><i class="fa fa-check"></i><b>6.1</b> Función de Probabilidad.</a></li>
<li class="chapter" data-level="6.2" data-path="función-de-distribución..html"><a href="función-de-distribución..html"><i class="fa fa-check"></i><b>6.2</b> Función de distribución.</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="función-de-distribución..html"><a href="función-de-distribución..html#propiedades-de-la-función-de-distribución."><i class="fa fa-check"></i><b>6.2.1</b> Propiedades de la función de distribución.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="cálculos-con-funciones-de-probabilidades..html"><a href="cálculos-con-funciones-de-probabilidades..html"><i class="fa fa-check"></i><b>6.3</b> Cálculos con funciones de probabilidades.</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="distribuciones-de-probabilidad-de-variables-discretas..html"><a href="distribuciones-de-probabilidad-de-variables-discretas..html"><i class="fa fa-check"></i><b>7</b> Distribuciones de probabilidad de variables discretas.</a></li>
<li class="chapter" data-level="8" data-path="distribuciones-de-probabilidad-de-variables-continuas..html"><a href="distribuciones-de-probabilidad-de-variables-continuas..html"><i class="fa fa-check"></i><b>8</b> Distribuciones de probabilidad de variables continuas.</a>
<ul>
<li class="chapter" data-level="8.1" data-path="distribución-normal..html"><a href="distribución-normal..html"><i class="fa fa-check"></i><b>8.1</b> Distribución Normal.</a></li>
<li class="chapter" data-level="8.2" data-path="distribución-ji-cuadrada..html"><a href="distribución-ji-cuadrada..html"><i class="fa fa-check"></i><b>8.2</b> Distribución Ji-Cuadrada.</a></li>
<li class="chapter" data-level="8.3" data-path="distribución-t-student..html"><a href="distribución-t-student..html"><i class="fa fa-check"></i><b>8.3</b> Distribución <span class="math inline">\(t\)</span>-Student.</a></li>
<li class="chapter" data-level="8.4" data-path="distribución-f..html"><a href="distribución-f..html"><i class="fa fa-check"></i><b>8.4</b> Distribución <span class="math inline">\(F\)</span>.</a></li>
<li class="chapter" data-level="8.5" data-path="ejercicios..html"><a href="ejercicios..html"><i class="fa fa-check"></i><b>8.5</b> Ejercicios.</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inferencia-estadística..html"><a href="inferencia-estadística..html"><i class="fa fa-check"></i><b>9</b> Inferencia Estadística.</a>
<ul>
<li class="chapter" data-level="9.1" data-path="cómo-se-enfrenta-a-la-inferencia-estadística.html"><a href="cómo-se-enfrenta-a-la-inferencia-estadística.html"><i class="fa fa-check"></i><b>9.1</b> ¿Cómo se enfrenta a la Inferencia Estadística?</a></li>
<li class="chapter" data-level="9.2" data-path="frecuentistas-y-muestreo-repetido..html"><a href="frecuentistas-y-muestreo-repetido..html"><i class="fa fa-check"></i><b>9.2</b> Frecuentistas y muestreo repetido.</a></li>
<li class="chapter" data-level="9.3" data-path="ámbito-de-la-inferencia-estadística..html"><a href="ámbito-de-la-inferencia-estadística..html"><i class="fa fa-check"></i><b>9.3</b> Ámbito de la inferencia Estadística.</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="teoría-de-muestreo..html"><a href="teoría-de-muestreo..html"><i class="fa fa-check"></i><b>10</b> Teoría de Muestreo.</a>
<ul>
<li class="chapter" data-level="10.1" data-path="estimación..html"><a href="estimación..html"><i class="fa fa-check"></i><b>10.1</b> Estimación.</a></li>
<li class="chapter" data-level="10.2" data-path="distribución-muestral-de-un-estimador..html"><a href="distribución-muestral-de-un-estimador..html"><i class="fa fa-check"></i><b>10.2</b> Distribución muestral de un estimador.</a></li>
<li class="chapter" data-level="10.3" data-path="teorema-del-límite-central-tlc..html"><a href="teorema-del-límite-central-tlc..html"><i class="fa fa-check"></i><b>10.3</b> Teorema del Límite Central (TLC).</a></li>
<li class="chapter" data-level="10.4" data-path="necesidad-de-especificar-una-muestra..html"><a href="necesidad-de-especificar-una-muestra..html"><i class="fa fa-check"></i><b>10.4</b> Necesidad de especificar una muestra.</a></li>
<li class="chapter" data-level="10.5" data-path="diseño-de-muestreo..html"><a href="diseño-de-muestreo..html"><i class="fa fa-check"></i><b>10.5</b> Diseño de muestreo.</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="diseño-de-muestreo..html"><a href="diseño-de-muestreo..html#muestreo-aleatorio-simple."><i class="fa fa-check"></i><b>10.5.1</b> Muestreo Aleatorio Simple.</a></li>
<li class="chapter" data-level="10.5.2" data-path="diseño-de-muestreo..html"><a href="diseño-de-muestreo..html#muestreo-aleatorio-estratificado."><i class="fa fa-check"></i><b>10.5.2</b> Muestreo Aleatorio Estratificado.</a></li>
<li class="chapter" data-level="10.5.3" data-path="diseño-de-muestreo..html"><a href="diseño-de-muestreo..html#muestreo-adaptativo."><i class="fa fa-check"></i><b>10.5.3</b> Muestreo Adaptativo.</a></li>
<li class="chapter" data-level="10.5.4" data-path="diseño-de-muestreo..html"><a href="diseño-de-muestreo..html#muestreo-sistemático."><i class="fa fa-check"></i><b>10.5.4</b> Muestreo Sistemático.</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="proceso-de-muestreo..html"><a href="proceso-de-muestreo..html"><i class="fa fa-check"></i><b>10.6</b> Proceso de Muestreo.</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="teoría-de-estimación..html"><a href="teoría-de-estimación..html"><i class="fa fa-check"></i><b>11</b> Teoría de Estimación.</a>
<ul>
<li class="chapter" data-level="11.1" data-path="propiedades-de-un-estimador..html"><a href="propiedades-de-un-estimador..html"><i class="fa fa-check"></i><b>11.1</b> Propiedades de un estimador.</a></li>
<li class="chapter" data-level="11.2" data-path="estimación-puntual..html"><a href="estimación-puntual..html"><i class="fa fa-check"></i><b>11.2</b> Estimación puntual.</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="estimación-puntual..html"><a href="estimación-puntual..html#construcción-de-estadísitcos-para-inferencia."><i class="fa fa-check"></i><b>11.2.1</b> Construcción de estadísitcos para inferencia.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="estimación-por-intervalos..html"><a href="estimación-por-intervalos..html"><i class="fa fa-check"></i><b>11.3</b> Estimación por Intervalos.</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="estimación-por-intervalos..html"><a href="estimación-por-intervalos..html#inferencia-sobre-la-media."><i class="fa fa-check"></i><b>11.3.1</b> Inferencia sobre la media.</a></li>
<li class="chapter" data-level="11.3.2" data-path="estimación-por-intervalos..html"><a href="estimación-por-intervalos..html#inferencia-sobre-la-varianza."><i class="fa fa-check"></i><b>11.3.2</b> Inferencia sobre la varianza.</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ejercicios.-1.html"><a href="ejercicios.-1.html"><i class="fa fa-check"></i><b>11.4</b> Ejercicios.</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="introducción-al-contraste-de-hipótesis..html"><a href="introducción-al-contraste-de-hipótesis..html"><i class="fa fa-check"></i><b>12</b> Introducción al Contraste de Hipótesis.</a>
<ul>
<li class="chapter" data-level="12.1" data-path="nos-podemos-equivocar.html"><a href="nos-podemos-equivocar.html"><i class="fa fa-check"></i><b>12.1</b> Nos podemos equivocar…</a></li>
<li class="chapter" data-level="12.2" data-path="estadístico-de-prueba..html"><a href="estadístico-de-prueba..html"><i class="fa fa-check"></i><b>12.2</b> Estadístico de Prueba.</a></li>
<li class="chapter" data-level="12.3" data-path="pz-ge-hatz.html"><a href="pz-ge-hatz.html"><i class="fa fa-check"></i><b>12.3</b> <span class="math display">\[P(Z \ge \hat{Z}) = ???\]</span></a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="pz-ge-hatz.html"><a href="pz-ge-hatz.html#región-crítica"><i class="fa fa-check"></i><b>12.3.1</b> Región crítica</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="el-p-valor-como-criterio-de-decisión..html"><a href="el-p-valor-como-criterio-de-decisión..html"><i class="fa fa-check"></i><b>12.4</b> El P-valor como criterio de decisión.</a></li>
<li class="chapter" data-level="12.5" data-path="beta-ptextrechazar-h_0-vert-h_1.html"><a href="beta-ptextrechazar-h_0-vert-h_1.html"><i class="fa fa-check"></i><b>12.5</b> <span class="math display">\[1 - \beta = P(\text{Rechazar }H_0 \vert H_1)\]</span></a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="beta-ptextrechazar-h_0-vert-h_1.html"><a href="beta-ptextrechazar-h_0-vert-h_1.html#errores-de-decisión."><i class="fa fa-check"></i><b>12.5.1</b> Errores de Decisión.</a></li>
<li class="chapter" data-level="12.5.2" data-path="beta-ptextrechazar-h_0-vert-h_1.html"><a href="beta-ptextrechazar-h_0-vert-h_1.html#pruebas-paramétricas-y-no-paramétricas."><i class="fa fa-check"></i><b>12.5.2</b> Pruebas paramétricas y no paramétricas.</a></li>
<li class="chapter" data-level="12.5.3" data-path="beta-ptextrechazar-h_0-vert-h_1.html"><a href="beta-ptextrechazar-h_0-vert-h_1.html#elección-de-la-prueba-estadistica."><i class="fa fa-check"></i><b>12.5.3</b> Elección de la prueba estadistica.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias..html"><a href="referencias..html"><i class="fa fa-check"></i>Referencias.</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown">
Proudly published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimación-puntual." class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Estimación puntual.<a href="estimación-puntual..html#estimación-puntual." class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cuando un investigador realiza un experimento, por lo general, solo toma una muestra represntativa de tamaño <span class="math inline">\(n\)</span> de la población de interés y calcula estimadores que le permitan describir los datos obtenidos y relalizar inferencias. El investigador no se moelsta en realizar el experiemnto varias veces (no es como las simulaciones, donde podiamos realizar repeticiones tantas como quisieramos. En la realidad, no se tiene el esfuerzo, la aneergía o los emdios apra realizar multiples repeticiones de un experimento). En estos casos se usan estimadores puntuales para poder realizar inferencias basados en solo una repetición del experimento.</p>
<blockquote>
<p>Un estimador puntual de un parámetro <span class="math inline">\(\theta\)</span>, es solo un valor <span class="math inline">\(\hat{\theta}\)</span> de un estadístico <span class="math inline">\(\hat{\Theta} = g(X)\)</span>. Para aclarar la notación, <span class="math inline">\(\hat{\Theta}\)</span> es el conjunto de todos los posibles valores del estadístico, y <span class="math inline">\(\hat{\theta}\)</span> es un elemento de ese conjunto particular, calculado a partir de una muestra.</p>
</blockquote>
<p>Veamos algunos ejemplos.</p>
<blockquote>
<p><em>Ejemplo</em>. Un experimento que busca evaluar la reacción de saltamontes a estímulos visuales o acústicos, en los que midieron el tiempo de reacción a estos antes del vuelo, encontraron que el tiempo de reacción promedio a estímulos acústicos es <span class="math inline">\(\bar{X}_a = 108{,}05\)</span> segundos, y a estímulos visuales es <span class="math inline">\(\bar{X}_v=87{,}19\)</span> segundos. Estos dos valores son estimadores puntuales de las medias poblacionales <span class="math inline">\(\mu_a\)</span> y <span class="math inline">\(\mu_v\)</span>.</p>
</blockquote>
<p>El siguiente, es un ejemplo que trata de enseñar como realizar estimaciones puntuales en diseños estratificados.</p>
<blockquote>
<p><em>Ejemplo.</em> Siniff y Skoog (1964) realizaron un muestreo aleatorio estratificado de una manada de caribúes de Nelchina en Alaska. Para ello, se establecieron 6 estratos (basados en estudios preliminares de la densidad relativa de los caribúes), y seleccionaron de manera aleatoria una muestra en cada uno de tamaño <span class="math inline">\(n_i\)</span> ( <span class="math inline">\(i=A, B, C, D, E, F\)</span> ), cada una de unidades muestrales de 4 millas cuadradas, obteniendose los datos mostrados en la tabla.<br />
Se desea saber el tamaño total de la población de caribúes.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left;">
Estrato
</th>
<th style="text-align:right;">
Tamaño del Estrato (<span class="math inline">\(S\)</span>)
</th>
<th style="text-align:right;">
Tamaño de muestra (<span class="math inline">\(N_h\)</span>)
</th>
<th style="text-align:right;">
Número promedio de Caribúes
</th>
<th style="text-align:right;">
Varianza
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
400
</td>
<td style="text-align:right;">
98
</td>
<td style="text-align:right;">
24.1
</td>
<td style="text-align:right;">
5575
</td>
</tr>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
25.6
</td>
<td style="text-align:right;">
4064
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:right;">
61
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
267.6
</td>
<td style="text-align:right;">
347556
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
179.0
</td>
<td style="text-align:right;">
22798
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:right;">
70
</td>
<td style="text-align:right;">
39
</td>
<td style="text-align:right;">
293.7
</td>
<td style="text-align:right;">
123578
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
33.2
</td>
<td style="text-align:right;">
9795
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:right;">
699
</td>
<td style="text-align:right;">
211
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Para poder conocer un estimado del tamaño poblacional total <span class="math inline">\(\hat{N}\)</span>, se necesita primero de un estimado del número promedio de caribúes por unidad de muestreo.
<span class="math display">\[
\begin{aligned}
\bar{X}_{ST} &amp;= \frac{\sum_{h=1}^L N_h \bar{x}_h}{N} \\
&amp;= \frac{400\times24{,}1 + 30\times25{,}6 + 61\times267{,}6 + \ldots}{699} \\
&amp;= 77{,}96\text{ caribúes milla}^{-2}
\end{aligned}
\]</span>
y se puede calcular la densidad de toda la población usando el total de millas cuadradas que conforman los estratos:
<span class="math display">\[\hat{N} = S \times \bar{X}_{ST} = 699\text{ milla}^2 \times 77{,}96\text{ caribúes milla}^{-2} = 54.597\text{ caribúes}\]</span>
Sabemos entonces, que el estimado del número de caribúes es <span class="math inline">\(\hat{N} = 54.597\text{ caribúes}\)</span>. Sin embargo, aun necesitamos cuantificar la incertidumbre asociada a esta estimación. Podemos calcular la varianza de <span class="math inline">\(\bar{X}_{ST}\)</span> como:
<span class="math display">\[Var(\bar{X}_{ST}) = \sum_{i=1}^L\left[ \frac{W_h^2 S_h^2}{n_h}(1 - f_h) \right]\]</span>
donde <span class="math inline">\(W_h = N_h / N\)</span> es el ponderado del estrato y <span class="math inline">\(f_h = n_h / N_h\)</span>. Usando los datos de la tabla:
<span class="math display">\[Var(\bar{X}_{ST}) = \left[ \frac{0{,}572^2 5575}{98} \right]\left(1 - \frac{98}{400}\right) + \left[ \frac{0{,}043^2 4064}{10} \right]\left(1 - \frac{10}{30}\right) + \ldots = 69{,}83\]</span>
de forma que la varianza del tamaño de la población de caribúes es <span class="math inline">\(69{,}83 \times 699^2 = 34.105.734\)</span>, y la desviación estándar es <span class="math inline">\(\sqrt{34.105.734} = 5.840\)</span> caribúes.<br />
Entonces el estimador buscado, con su medida de incertidumbre, es <span class="math display">\[54.597 \pm 5.840 \text{ caribúes}\]</span></p>
</blockquote>
<p>El siguiente ejemplo, es uno donde se construye un estadístico a partir de otro que tiene una ley de probabilidad prespecificada. De esta forma, podemos facilitar la obtención de una distribución muestral asociada al nuevo estadistico que permita ontener medidas de probabilidad asociada a valores observados particulares.</p>
<blockquote>
<p><em>Ejemplo</em>. Digamos que tenemos una estimador puntual que queremos evaluar, digamos, la media calculada <span class="math inline">\(\bar{X}\)</span> de una muestra de tamaño <span class="math inline">\(n\)</span>, en cuanto a la probabilidad de ocurrencia de este. El TLC nos indica que este estimador se distribuye normalmente (si conocemos la varianza poblacional o si el <span class="math inline">\(n\)</span> es lo suficientemente grande como para asumir que conocemos la varianza poblacional lo suficientemente bien). Escribimos entonces el estimador puntual
<span class="math display">\[\hat{Z} = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\]</span>
Como vimos en la sección [distribucion-normal], este se puede usar para encontrar valores de probabilidad asociado a obtener un valor de a lo sumo <span class="math inline">\(\bar{X}\)</span> como:
<span class="math display">\[P(X \le \bar{X}) = P(Z \le\hat{Z})\]</span></p>
</blockquote>
<div id="construcción-de-estadísitcos-para-inferencia." class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Construcción de estadísitcos para inferencia.<a href="estimación-puntual..html#construcción-de-estadísitcos-para-inferencia." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El ejemplo anterior es muy importante.
Nos dice que si podemos asumir una distribución para una variable aleatoria, entonces podemos construir un estadístico con el cual facilitar la obtención de medidas de probabilidad.
Esto nos da una forma sencilla de encontrar probabilidades asociadas a un estimador particular calculado a partir de una muestra, y así, poder obtener medidas de incertidumbre que nos permitan derivar conclusiones adecuadas sobre los estimadores.</p>
<p><strong>Estadístico sobre la media</strong></p>
<p>Los estadísticos sobre la media los podemos escribir usando el TLC como base para realizar inferencia.
Si tenemos un conjunto de v. a. <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> independientes e identicamente distribuidas como <span class="math inline">\(f(\theta)\)</span>, de las cuales se hacen las observaciones <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>, de la cual estimamos el valor <span class="math inline">\(\hat{\theta}\)</span>, entonces podemos construir un estadístico sobre <span class="math inline">\(\theta\)</span> como:</p>
<p><span class="math display">\[\frac{\hat{\theta} - \theta}{SE(\theta)}\]</span></p>
<p>Este estadístico lo podemos entender al darnos cuenta de dos cosas:</p>
<ul>
<li>El uso de la diferencia <span class="math inline">\(\hat{\theta} - \theta\)</span> sirve como una medida de similitud entre el estimador <span class="math inline">\(\hat{\theta}\)</span> y el valor real del parámetro <span class="math inline">\(\theta\)</span>: valores grandes inidcan que ambos son menos aprecidos entre sí, mientras que valores pequeños de esta diferencia indican que el estimador y el parámetro son más similares entre sí.</li>
<li>De igual forma, el signo de la diferencia nos dice la dirección en la que cae el estimador: valores positivos indican que se tienen valores por encima del valor del parámetro, mientras que un signo negativo indica que el valor estimado cae por debajo del verdadero valor del parámetro.</li>
<li>Al dividir la diferencia entre el error estándar <span class="math inline">\(SE(\theta)\)</span>, lo que se hace es estandarizar la diferencia. De esta forma, las diferencias las podemos entender como desviaciones estándar, esto es, a cuantas desviaciones estándar el estimador cae del parámetro.</li>
</ul>
<p>En este caso, se asume que el error estándar es conocido, de forma que el estadístico sigue una distribución normal estándar (según el TLC), y se escribe:</p>
<p><span class="math display">\[\hat{Z} = \frac{\hat{\theta} - \theta}{SE(\theta)} \sim N(0, 1)\]</span></p>
<p>La ecuación anterior también es válida aun si tebnemos que calcular el error estándar de los datos, siempre y cuando el tamaño de la muestra recolectada para estimar <span class="math inline">\(SE(\theta)\)</span> sea lo suficientemente grande como para asegurarnos de que sabemos su valor con una exactitud adecuada.</p>
<p>Si, por otro lado, no conocemos el verdadero valor de <span class="math inline">\(SE(\theta)\)</span> y la muestra de donde estimamos a este es muy pequeña, entonces debemos asumir que este es una variable aletoria más.
La distribución muestral del nuevo estadístico la podemos obtener notando que:</p>
<p><span class="math display">\[SE(\hat{\theta}) = \frac{\hat{\sigma}}{\sqrt{n}}\]</span></p>
<p>donde <span class="math inline">\(\hat{\sigma}^2 \sim \chi^2(n - 1)\)</span>, y por la proposición final en la sección [distribución-<span class="math inline">\(t\)</span>-student], entonces el estadístico sigue una distribución <span class="math inline">\(t\)</span>-Student y se escribe como:</p>
<p><span class="math display">\[\hat{t} = \frac{\hat{\theta} - \theta}{SE(\hat{\theta})} \sim t(n - 1)\]</span></p>
<p>Con este esquema general, podremos realizar inferencias con respecto a la media y otros parámetros, como veremos en la siguiente sección.
Pero antes, veamos como construir un estadístico sobre la varianza.</p>
<p><strong>Estadístico sobre la varianza</strong></p>
<p>Antes usamos la diferencia entre el estimador y el parámetro para construir un estadístico que nos dijera que tan similares son.
Este argumento funciona bien con estadísticos como la media, ya que este corresponde a una medida de locación, y la lejanía de dos locaciones (numericamente hablando) nos permite entender que tan similares son (ve la figura <a href="#fig:location-var"><strong>??</strong></a>).
Con las varianzas, el argumento de la diferncia no es tan intuitivo. Si queremos saber si una varianza es mayor o menor que otra, resulta más intuitivo verificar qaue tanto mayor (o menor) es la dispersión de una poblacion con respecto a otra.
Esto apunta al uso de cocientes entre varianzas.</p>
<p>Si tenemos un conjunto de v. a. <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> independientes e identicamente distribuidas como <span class="math inline">\(f(\theta)\)</span>, de las cuales se hacen las observaciones <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>, de la cual estimamos la varianza <span class="math inline">\(S^2\)</span>, entonces podemos construir un estadístico sobre <span class="math inline">\(S^2\)</span> como:</p>
<p><span class="math display">\[\frac{(n - 1) S^2}{\sigma^2}\]</span></p>
<p>la cual sabemos, por la proposición que vimos al final de la sección [distribucion-ji-cuadrada] sabemos se distribuye como una distribución <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n - 1\)</span> grados de libertad, por lo que podemos escrbir:</p>
<p><span class="math display">\[X^2 = \frac{(n - 1) S^2}{\sigma^2} \sim \chi^2(n - 1)\]</span></p>
<p>Se tiene entonces que:</p>
<ul>
<li>Si la muestra proviene de la misma población, el valor esperado de la varianza <span class="math inline">\(E[S^2]\)</span> será <span class="math inline">\(\sigma^2\)</span> y el valor esperado del cociente será <span class="math inline">\(E[(n - 1) S^2 / \sigma^2] = \frac{(n - 1)}{\sigma^2} E[S^2] = n - 1\)</span>. Este valor resulta que coprresponde a la media de la distribución <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n - 1\)</span> grados de libertad.</li>
<li>Si la muestra proviene de una población con un varianza menor, entonces el valor esperado <span class="math inline">\(E[S^2]\)</span> es menor que <span class="math inline">\(\sigma^2\)</span>, por lo que el cociente <span class="math inline">\(\frac{(n - 1)}{\sigma^2} E[S^2] &lt; n - 1\)</span>.</li>
<li>Si la muestra proviene de una población con un varianza mayor, entonces el valor esperado <span class="math inline">\(E[S^2]\)</span> es mayor que <span class="math inline">\(\sigma^2\)</span>, por lo que el cociente <span class="math inline">\(\frac{(n - 1)}{\sigma^2} E[S^2] &gt; n - 1\)</span>.</li>
</ul>
<p>Los casos anteriores corresponden a lo que esperaríamos a la larga (si repitieramos muchas veces el experimento).
Pero hay que entender, que al hacer el experimento y recolectar una muestra, el valor etimado de <span class="math inline">\(S^2\)</span> puede ser menor o mayor que <span class="math inline">\(\sigma^2\)</span> solo por efecto del azar.
Podemos calcular entonces que tan probable es que el valor sea tan grande como el encontrado usando la distribución muestral, <span class="math inline">\(P(\chi^2 \ge X^2)\)</span>.</p>
<p>Ahora, el procedimiento anterior es útil cuando queremos verificar si la variansza calculada de una muestra, corresponde con la varianza conocida para la población de donde se tomo la muestra.
Pero podriamos querer comparar dos poblaciones distintas, para verificar si sus varianzas son las mismas.
En este caso, supongamos que las varianzas de las poblaciones son <span class="math inline">\(\sigma_1^2\)</span> y <span class="math inline">\(\sigma_2^2\)</span>, cuyos estimadores respectivos son <span class="math inline">\(S_1^2\)</span> y <span class="math inline">\(S_2^2\)</span>, calculados a partir de muestras de tamaño <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span>, respectivamente.
Podemos usar una parte de estadístico que construimos antes para cada una de las varianzas:</p>
<p><span class="math display">\[\frac{(n_i - 1) S_i^2}{\sigma_i^2}\]</span></p>
<p>para <span class="math inline">\(i = 1\)</span> y <span class="math inline">\(2\)</span>, que sabemos corresponden a una v. a. que siguen una distribución <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n_i - 1\)</span> grados de libertad.
Entonces, podemos usar la proposición final de la sección [distribucion-f] para verificar que</p>
<p><span class="math display">\[\frac{S_1^2 / \sigma_1^2}{S_2^2 / \sigma_2^2} = \frac{\sigma_2^2 S_1^2}{\sigma_1^2 S_2^2}\]</span></p>
<p>sigue una distribución <span class="math inline">\(F\)</span> con <span class="math inline">\(n_1 - 1\)</span> y <span class="math inline">\(n_2 - 1\)</span> grados de libertad, y se puede escribir:</p>
<p><span class="math display">\[\hat{F} = \frac{\sigma_2^2 S_1^2}{\sigma_1^2 S_2^2} \sim F(n_1 -1, n_2 - 1)\]</span></p>
<p>El valor esperado para esta distribución es ligeramente mayor a uno para tamaños de muestra muy pequeño, y es aproximadamente de uno para tamaños de muestra grande. De forma que:
si el valor es mayor o menor a uno, podríamos hablar sobre varianzas que no son iguales, y por tanto, las muestras son obtenidas de poblaciones distintas.
De nuevo, esto es en un sentido estadístico: la muestra puede resultar en proporciones de varianzas distintas a uno solo por azar. Podemos calcular que tan probable es que el valor sea tan grande como el encontrado usando la distribución muestral, <span class="math inline">\(P(F \ge \hat{F})\)</span>.</p>
<p>Usando este esquema general (los estadísticos construidos), podemos cuantificar la incertidumbre con respecto a un parámetro en problemas de inferencia como sigue en la siguiente sección.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="propiedades-de-un-estimador..html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimación-por-intervalos..html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
